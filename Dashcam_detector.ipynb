{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d47898f-42d9-492a-bd9c-cea3e9b5d814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 29 22:38:09 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650        Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   53C    P8               4W /  50W |    584MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2074      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A      5201      C   ...iniconda3/envs/fish_tank/bin/python      576MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d06a5dcb-b401-4819-8614-6ac591975c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervision 0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install supervision==0.2.0\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import supervision as sv\n",
    "print(\"supervision\", sv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf6346cc-61cf-4fc9-8629-97f5527ddb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cf17c1d-0598-4138-a854-8e951c76eed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sukuna/Documents/PROJECTS/Dashcamdetector\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11335cbb-4e81-475e-a9cd-15488beb37cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sukuna/miniconda3/envs/fish_tank/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sukuna/Documents/PROJECTS/Dashcamdetector\n",
      "--2024-04-29 21:03:37--  https://docs.google.com/uc?export=download&confirm=&id=1M3UuH3QNDWGiH0NmGgHtIgXXGDo_nigm\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.195.174, 2404:6800:4007:826::200e\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.195.174|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://drive.usercontent.google.com/download?id=1M3UuH3QNDWGiH0NmGgHtIgXXGDo_nigm&export=download [following]\n",
      "--2024-04-29 21:03:40--  https://drive.usercontent.google.com/download?id=1M3UuH3QNDWGiH0NmGgHtIgXXGDo_nigm&export=download\n",
      "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.250.195.193, 2404:6800:4007:827::2001\n",
      "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.250.195.193|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 103282086 (98M) [video/mp4]\n",
      "Saving to: ‘mall.mp4’\n",
      "\n",
      "mall.mp4            100%[===================>]  98.50M   538KB/s    in 3m 20s  \n",
      "\n",
      "2024-04-29 21:07:06 (504 KB/s) - ‘mall.mp4’ saved [103282086/103282086]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1M3UuH3QNDWGiH0NmGgHtIgXXGDo_nigm' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1M3UuH3QNDWGiH0NmGgHtIgXXGDo_nigm\" -O mall.mp4 && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86322c20-4e4a-4897-90bd-fae07a841b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "MALL_VIDEO_PATH = f\"{HOME}/mall.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bd85e66-accb-4982-be56-4ff78b4a0134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 1 person, 4 bottles, 1 chair, 1 tv, 2 refrigerators, 39.5ms\n",
      "Speed: 11.8ms preprocess, 39.5ms inference, 1.1ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SupervisionWarnings: annotate is deprecated: `BoxAnnotator` is deprecated and will be removed in `supervision-0.22.0`. Use `BoundingBoxAnnotator` and `LabelAnnotator` instead\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can't convert object to 'str' for 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# sv.show_frame_in_notebook(frame, (16, 16))\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(x)\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't convert object to 'str' for 'filename'"
     ]
    }
   ],
   "source": [
    "import supervision as sv\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# extract video frame\n",
    "generator = sv.get_video_frames_generator(MALL_VIDEO_PATH)\n",
    "iterator = iter(generator)\n",
    "frame = next(iterator)\n",
    "\n",
    "# detect\n",
    "results = model(frame, imgsz=1280)[0]\n",
    "detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "# annotate\n",
    "box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
    "frame = box_annotator.annotate(scene=frame, detections=detections)\n",
    "\n",
    "%matplotlib inline  \n",
    "# sv.show_frame_in_notebook(frame, (16, 16))\n",
    "\n",
    "x = cv.imread(frame)\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c3c6446-4c3d-43c3-8a91-c46e6308aecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 1 person, 4 bottles, 1 chair, 1 tv, 2 refrigerators, 46.7ms\n",
      "Speed: 8.7ms preprocess, 46.7ms inference, 1520.3ms postprocess per image at shape (1, 3, 736, 1280)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'Detections' has no attribute 'from_yolov8'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# detect\u001b[39;00m\n\u001b[1;32m     14\u001b[0m results \u001b[38;5;241m=\u001b[39m model(frame, imgsz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1280\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m detections \u001b[38;5;241m=\u001b[39m \u001b[43msv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDetections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_yolov8\u001b[49m(results)\n\u001b[1;32m     16\u001b[0m detections \u001b[38;5;241m=\u001b[39m detections[detections\u001b[38;5;241m.\u001b[39mclass_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# annotate\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Detections' has no attribute 'from_yolov8'"
     ]
    }
   ],
   "source": [
    "import supervision as sv\n",
    "\n",
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "\n",
    "\n",
    "\n",
    "# extract video frame\n",
    "generator = sv.get_video_frames_generator(MALL_VIDEO_PATH)\n",
    "iterator = iter(generator)\n",
    "frame = next(iterator)\n",
    "\n",
    "# detect\n",
    "results = model(frame, imgsz=1280)[0]\n",
    "detections = sv.Detections.from_yolov8(results)\n",
    "detections = detections[detections.class_id == 0]\n",
    "\n",
    "# annotate\n",
    "box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
    "labels = [f\"{model.names[class_id]} {confidence:0.2f}\" for _, confidence, class_id, _ in detections]\n",
    "frame = box_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
    "\n",
    "%matplotlib inline  \n",
    "sv.show_frame_in_notebook(frame, (16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe90c2-efd7-4338-a191-04d0f7b5041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate polygon zone\n",
    "polygon = np.array([\n",
    "    [1900, 1250],\n",
    "    [2350, 1250],\n",
    "    [3500, 2160],\n",
    "    [1250, 2160]\n",
    "])\n",
    "video_info = sv.VideoInfo.from_video_path(\"dash.mp4\")\n",
    "zone = sv.PolygonZone(polygon=polygon, frame_resolution_wh=video_info.resolution_wh)\n",
    "\n",
    "# initiate annotators\n",
    "box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
    "zone_annotator = sv.PolygonZoneAnnotator(zone=zone, color=sv.Color.white(), thickness=6, text_thickness=6, text_scale=4)\n",
    "\n",
    "# extract video frame\n",
    "generator = sv.get_video_frames_generator(MALL_VIDEO_PATH)\n",
    "iterator = iter(generator)\n",
    "frame = next(iterator)\n",
    "\n",
    "# detect\n",
    "results = model(frame, imgsz=1280)[0]\n",
    "detections = sv.Detections.from_yolov8(results)\n",
    "detections = detections[detections.class_id == 0]\n",
    "zone.trigger(detections=detections)\n",
    "\n",
    "# annotate\n",
    "box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
    "labels = [f\"{model.names[class_id]} {confidence:0.2f}\" for _, confidence, class_id, _ in detections]\n",
    "frame = box_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
    "frame = zone_annotator.annotate(scene=frame)\n",
    "\n",
    "%matplotlib inline  \n",
    "sv.show_frame_in_notebook(frame, (16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abbcf074-d671-401e-9033-3df104e6099b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[133 143 147]\n",
      "  [133 143 147]\n",
      "  [133 143 147]\n",
      "  ...\n",
      "  [ 18 198 251]\n",
      "  [ 21 196 250]\n",
      "  [ 21 196 250]]\n",
      "\n",
      " [[133 143 147]\n",
      "  [133 143 147]\n",
      "  [133 143 147]\n",
      "  ...\n",
      "  [ 18 198 251]\n",
      "  [ 21 196 250]\n",
      "  [ 21 196 250]]\n",
      "\n",
      " [[133 143 147]\n",
      "  [133 143 147]\n",
      "  [133 143 147]\n",
      "  ...\n",
      "  [ 14 198 251]\n",
      "  [ 17 197 250]\n",
      "  [ 17 197 250]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 35  28  34]\n",
      "  [ 35  28  34]\n",
      "  [ 35  28  34]\n",
      "  ...\n",
      "  [ 44  56  43]\n",
      "  [ 44  56  43]\n",
      "  [ 44  56  43]]\n",
      "\n",
      " [[ 42  33  44]\n",
      "  [ 42  33  44]\n",
      "  [ 42  33  44]\n",
      "  ...\n",
      "  [ 44  56  43]\n",
      "  [ 44  56  43]\n",
      "  [ 44  56  43]]\n",
      "\n",
      " [[ 45  36  47]\n",
      "  [ 45  36  47]\n",
      "  [ 45  36  47]\n",
      "  ...\n",
      "  [ 44  56  43]\n",
      "  [ 44  56  43]\n",
      "  [ 44  56  43]]]\n"
     ]
    }
   ],
   "source": [
    "# generator = sv.get_video_frames_generator(MALL_VIDEO_PATH)\n",
    "# iterator = iter(generator)\n",
    "# frame = next(iterator)\n",
    "print(frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
